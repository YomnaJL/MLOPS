{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b8406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports termin√©s\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ML Models\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Imports termin√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc0b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "import mlflow.catboost\n",
    "import dagshub\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, precision_score, recall_score,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1ea65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System detected user: pc\n",
      "üë§ MLflow User set to: imen benamar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as ImenBenAmar\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as ImenBenAmar\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"YomnaJL/MLOPS_Project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"YomnaJL/MLOPS_Project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository YomnaJL/MLOPS_Project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository YomnaJL/MLOPS_Project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow Configured via DagsHub\n",
      "üìä Tracking URI: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow\n",
      "üß™ Experiment: Crime_MLOPS1\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "import getpass\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "DAGSHUB_USERNAME = os.getenv('DAGSHUB_USERNAME')\n",
    "DAGSHUB_TOKEN = os.getenv('DAGSHUB_TOKEN')\n",
    "DAGSHUB_REPO = os.getenv('DAGSHUB_REPO_NAME')\n",
    "EXPERIMENT_NAME = \"Crime_MLOPS1\"\n",
    "DATA_PATH = '../processors/preprocessed_data.pkl'\n",
    "\n",
    "# --- INTERACTIVE USER INPUT ---\n",
    "system_user = getpass.getuser()\n",
    "print(f\"\\nSystem detected user: {system_user}\")\n",
    "custom_user = input(f\"Enter username for MLflow tagging (Press Enter to use '{system_user}'): \")\n",
    "user_name = custom_user.strip() if custom_user.strip() else system_user\n",
    "print(f\"üë§ MLflow User set to: {user_name}\")\n",
    "USER_NAME=user_name\n",
    "\n",
    "# --- Initialize DagsHub & MLflow ---\n",
    "if all([DAGSHUB_USERNAME, DAGSHUB_TOKEN, DAGSHUB_REPO]):\n",
    "    # Set environment variables BEFORE any MLflow calls\n",
    "    os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USERNAME\n",
    "    os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN\n",
    "    os.environ['MLFLOW_ENABLE_LOGGED_MODEL_CREATION'] = 'false'\n",
    "    \n",
    "    MLFLOW_TRACKING_URI = f\"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO}.mlflow\"\n",
    "    \n",
    "    # 1. Initialize DagsHub (This handles auth setup internally)\n",
    "    dagshub.init(repo_owner=DAGSHUB_USERNAME, repo_name=DAGSHUB_REPO, mlflow=True)\n",
    "    \n",
    "    # 2. Explicitly set tracking URI\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    \n",
    "    # 3. Create or Set Experiment\n",
    "    try:\n",
    "        # Check if experiment exists\n",
    "        experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "        if experiment is None:\n",
    "            mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error setting experiment: {e}\")\n",
    "\n",
    "    print(f\"‚úÖ MLflow Configured via DagsHub\")\n",
    "    print(f\"üìä Tracking URI: {MLFLOW_TRACKING_URI}\")\n",
    "    print(f\"üß™ Experiment: {EXPERIMENT_NAME}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Missing .env variables. Running locally only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Loaded Successfully\n",
      "   Train Shape: (319110, 17)\n",
      "   Test Shape:  (79778, 17)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Data file '{DATA_PATH}' not found. Run preprocessing first.\")\n",
    "\n",
    "with open(DATA_PATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train = data['X_train_scaled']\n",
    "X_test = data['X_test_scaled']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "\n",
    "print(f\"‚úÖ Data Loaded Successfully\")\n",
    "print(f\"   Train Shape: {X_train.shape}\")\n",
    "print(f\"   Test Shape:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import time\n",
    "\n",
    "# Global Leaderboard\n",
    "leaderboard = pd.DataFrame(columns=[\"Stage\", \"Model\", \"Accuracy\", \"F1_Weighted\", \"ROC_AUC\", \"Time (s)\"])\n",
    "\n",
    "def get_run_input(model_name, stage):\n",
    "    \"\"\"Pauses execution to ask for metadata for the specific model.\"\"\"\n",
    "    print(f\"\\nüìù Configuring: {model_name} ({stage})\")\n",
    "    print(\"-\" * 40)\n",
    "    def_ver = \"V1\"\n",
    "    def_desc = f\"{stage} training for {model_name}\"\n",
    "    \n",
    "    ver = input(f\"   Dataset Version [Enter='{def_ver}']: \")\n",
    "    desc = input(f\"   Description     [Enter='{def_desc}']: \")\n",
    "    \n",
    "    return ver.strip() or def_ver, desc.strip() or def_desc\n",
    "\n",
    "def log_confusion_matrix(y_true, y_pred, model_name, stage):\n",
    "    \"\"\"Generates, saves and logs Confusion Matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {model_name} ({stage})')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    filename = f\"cm_{model_name}_{stage}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    \n",
    "    mlflow.log_artifact(filename)\n",
    "    if os.path.exists(filename): os.remove(filename)\n",
    "\n",
    "def log_roc_curve(y_true, y_prob, model_name, stage):\n",
    "    \"\"\"Generates, saves and logs ROC-AUC Curve (One-vs-Rest).\"\"\"\n",
    "    if y_prob is None: return\n",
    "\n",
    "    n_classes = y_prob.shape[1]\n",
    "    # Binarize labels for ROC calculation\n",
    "    classes = np.unique(y_true)\n",
    "    y_bin = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Calculate ROC for each class\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_bin[:, i], y_prob[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'Class {i} (area = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name} ({stage})')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    filename = f\"roc_{model_name}_{stage}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    \n",
    "    mlflow.log_artifact(filename)\n",
    "    if os.path.exists(filename): os.remove(filename)\n",
    "\n",
    "def train_evaluate_log(model_name, model, X_train, y_train, X_test, y_test, stage, \n",
    "                       dataset_version, description, params=None, tune=False, param_dist=None, n_iter=6):\n",
    "    \n",
    "    global leaderboard\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"{model_name}_{stage}\", description=description):\n",
    "        # Tags\n",
    "        mlflow.set_tag(\"user\", USER_NAME)\n",
    "        mlflow.set_tag(\"dataset_version\", dataset_version)\n",
    "        mlflow.set_tag(\"model_name\", model_name)\n",
    "        mlflow.set_tag(\"stage\", stage)\n",
    "        \n",
    "        # Tuning\n",
    "        tune_time = 0\n",
    "        final_model = model\n",
    "        if tune and param_dist:\n",
    "            start_tune = time.time()\n",
    "            search = RandomizedSearchCV(model, param_dist, n_iter=n_iter, scoring='f1_weighted', cv=3, verbose=0, n_jobs=-1, random_state=42)\n",
    "            search.fit(X_train, y_train)\n",
    "            tune_time = time.time() - start_tune\n",
    "            final_model = search.best_estimator_\n",
    "            params = search.best_params_\n",
    "            mlflow.log_metric(\"tuning_time\", tune_time)\n",
    "        \n",
    "        if params: mlflow.log_params(params)\n",
    "\n",
    "        # Training\n",
    "        start_train = time.time()\n",
    "        if not tune: final_model.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_train\n",
    "        \n",
    "        # Prediction\n",
    "        start_pred = time.time()\n",
    "        y_pred = final_model.predict(X_test)\n",
    "        pred_time = time.time() - start_pred\n",
    "        \n",
    "        try: y_prob = final_model.predict_proba(X_test)\n",
    "        except: y_prob = None\n",
    "\n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        roc_auc = 0\n",
    "        if y_prob is not None:\n",
    "             try: roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
    "             except: pass\n",
    "\n",
    "        # Log Metrics\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_weighted\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        if not tune: mlflow.log_metric(\"training_time\", train_time)\n",
    "\n",
    "        # Save Model\n",
    "        try:\n",
    "            fname = f\"{model_name}_{stage}.pkl\"\n",
    "            with open(fname, \"wb\") as f: pickle.dump(final_model, f)\n",
    "            mlflow.log_artifact(fname)\n",
    "            if os.path.exists(fname): os.remove(fname)\n",
    "        except: pass\n",
    "\n",
    "        # --- LOG IMAGES ---\n",
    "        log_confusion_matrix(y_test, y_pred, model_name, stage)\n",
    "        log_roc_curve(y_test, y_prob, model_name, stage)\n",
    "        \n",
    "        # Update Leaderboard\n",
    "        new_row = pd.DataFrame([{\n",
    "            \"Stage\": stage, \"Model\": model_name, \n",
    "            \"Accuracy\": acc, \"F1_Weighted\": f1, \n",
    "            \"ROC_AUC\": roc_auc, \"Time (s)\": train_time + tune_time\n",
    "        }])\n",
    "        leaderboard = pd.concat([leaderboard, new_row], ignore_index=True)\n",
    "        \n",
    "        return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Baseline Configurations ---\n",
    "base_models_config = {\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=150, max_depth=15, class_weight='balanced', n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=150, learning_rate=0.1, max_depth=6, eval_metric='mlogloss', n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=150, learning_rate=0.1, class_weight='balanced', n_jobs=-1, random_state=42, verbose=-1\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostClassifier(\n",
    "        iterations=150, learning_rate=0.1, depth=6, verbose=0, random_state=42, allow_writing_files=False\n",
    "    )\n",
    "}\n",
    "\n",
    "# --- Hyperparameter Grids ---\n",
    "param_grids = {\n",
    "    'RandomForest': { \n",
    "        'n_estimators': [100, 300, 600],\n",
    "            'max_depth': [10,30, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 3, 6],\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'class_weight': ['balanced', 'balanced_subsample']\n",
    "    },\n",
    "    'XGBoost': { \n",
    "        'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 5, 7, 10],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "            'gamma': [0, 0.1, 0.2],\n",
    "            'min_child_weight': [1, 3, 5]\n",
    "    },\n",
    "    'LightGBM': { \n",
    "        'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [-1, 10, 20],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'num_leaves': [20, 31, 50, 100],\n",
    "            'min_child_samples': [10, 20, 30],\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "            'class_weight': ['balanced', None]\n",
    "    },\n",
    "    'CatBoost': { \n",
    "        'iterations': [100, 200, 300],\n",
    "            'depth': [4, 6, 8, 10],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "            'random_strength': [1, 2, 5],\n",
    "            'auto_class_weights': ['Balanced', 'None']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dictionaries to store trained instances\n",
    "trained_baseline = {}\n",
    "trained_tuned = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "‚ñ∂Ô∏è  Phase 1: Baseline Models\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Models:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Configuring: RandomForest (Baseline)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run RandomForest_Baseline at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/962ebae059894035976279f8e324c362\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Models:  25%|‚ñà‚ñà‚ñå       | 1/4 [06:52<20:37, 412.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Configuring: XGBoost (Baseline)\n",
      "----------------------------------------\n",
      "üèÉ View run XGBoost_Baseline at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/9b4a85cfd0c040ff8fe1259737b1772d\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Models:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [10:49<10:17, 308.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Configuring: LightGBM (Baseline)\n",
      "----------------------------------------\n",
      "üèÉ View run LightGBM_Baseline at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/a75eecf0ff354ca3954d2e7d4086fc0d\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Models:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [11:57<03:19, 199.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Configuring: CatBoost (Baseline)\n",
      "----------------------------------------\n",
      "üèÉ View run CatBoost_Baseline at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/ed57771e298242b6babd54377765fa11\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Models: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [12:54<00:00, 193.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "‚ñ∂Ô∏è  Phase 2: Hyperparameter Tuning\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Models:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Configuring: RandomForest (Tuned)\n",
      "----------------------------------------\n",
      "üèÉ View run RandomForest_Tuned at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/0a280f5dfd5141ec92ac02b6272c5cc7\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Models:  25%|‚ñà‚ñà‚ñå       | 1/4 [22:05<1:06:15, 1325.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Configuring: XGBoost (Tuned)\n",
      "----------------------------------------\n",
      "üèÉ View run XGBoost_Tuned at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/6f4bb9bb6a154195bdf1df06359cc1a1\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Models:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [33:39<31:47, 953.91s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Configuring: LightGBM (Tuned)\n",
      "----------------------------------------\n",
      "üèÉ View run LightGBM_Tuned at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/27827760550d41cc933a64dc4938226e\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Models:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [55:21<18:32, 1112.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Configuring: CatBoost (Tuned)\n",
      "----------------------------------------\n",
      "üèÉ View run CatBoost_Tuned at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/66a520c8050f4d85b93ea292275ad0d2\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Models: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [1:10:47<00:00, 1062.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "‚ñ∂Ô∏è  Phase 3: Stacking Ensembles\n",
      "--------------------------------------------------\n",
      "\n",
      "üìù Configuring: StackingClassifier (Ensemble_Baseline)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run StackingClassifier_Ensemble_Baseline at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/d9f182f672f4447f955a88a8479e769a\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n",
      "\n",
      "üìù Configuring: StackingClassifier (Ensemble_Tuned)\n",
      "----------------------------------------\n",
      "üèÉ View run StackingClassifier_Ensemble_Tuned at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2/runs/5a9f4ea8f69c4b2689b7d413c2b17b55\n",
      "üß™ View experiment at: https://dagshub.com/YomnaJL/MLOPS_Project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 87] Param√®tre incorrect",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"d:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 373, in _sendback_result\n    result_queue.put(\n  File \"d:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 233, in put\n    self._writer.send_bytes(obj)\n  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py\", line 205, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py\", line 285, in _send_bytes\n    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\nOSError: [WinError 87] Param√®tre incorrect\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m ver, desc \u001b[38;5;241m=\u001b[39m get_run_input(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStackingClassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemble_Tuned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m stack_tuned \u001b[38;5;241m=\u001b[39m StackingClassifier(estimators\u001b[38;5;241m=\u001b[39m[(n, m) \u001b[38;5;28;01mfor\u001b[39;00m n, m \u001b[38;5;129;01min\u001b[39;00m trained_tuned\u001b[38;5;241m.\u001b[39mitems()], final_estimator\u001b[38;5;241m=\u001b[39mLogisticRegression(), n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mtrain_evaluate_log\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStackingClassifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack_tuned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnsemble_Tuned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Final Display\u001b[39;00m\n\u001b[0;32m     59\u001b[0m display(leaderboard\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1_Weighted\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mbackground_gradient(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1_Weighted\u001b[39m\u001b[38;5;124m\"\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGreens\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[1;32mIn[5], line 96\u001b[0m, in \u001b[0;36mtrain_evaluate_log\u001b[1;34m(model_name, model, X_train, y_train, X_test, y_test, stage, dataset_version, description, params, tune, param_dist, n_iter)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m     95\u001b[0m start_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tune: \u001b[43mfinal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_train\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:706\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    704\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m--> 706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y_encoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:211\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mappend(estimator)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Fit the base estimators on the whole training data. Those\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# base estimators will be used in transform, predict, and\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# predict_proba. They are exposed publicly.\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[0;32m    220\u001b[0m est_fitted_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\joblib\\parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1784\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     nb_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\joblib\\parallel.py:1859\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\joblib\\parallel.py:758\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    752\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\mlops\\classe\\MLOPS\\venv\\lib\\site-packages\\joblib\\parallel.py:773\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 773\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 87] Param√®tre incorrect"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Baseline Models\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n‚ñ∂Ô∏è  Phase 1: Baseline Models\\n\" + \"-\"*50)\n",
    "\n",
    "# We iterate using keys to allow input before training\n",
    "for name in tqdm(base_models_config.keys(), desc=\"Baseline Models\"):\n",
    "    model_inst = base_models_config[name]\n",
    "    \n",
    "    # Ask for input\n",
    "    ver, desc = get_run_input(name, \"Baseline\")\n",
    "    \n",
    "    # Train & Log\n",
    "    m = train_evaluate_log(\n",
    "        model_name=name,\n",
    "        model=model_inst,\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        X_test=X_test, y_test=y_test,\n",
    "        stage=\"Baseline\",\n",
    "        dataset_version=ver,\n",
    "        description=desc\n",
    "    )\n",
    "    trained_baseline[name] = m\n",
    "\n",
    "# 2. Tuning Models\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n‚ñ∂Ô∏è  Phase 2: Hyperparameter Tuning\\n\" + \"-\"*50)\n",
    "for name in tqdm(base_models_config.keys(), desc=\"Tuning Models\"):\n",
    "    if name in param_grids:\n",
    "        model_inst = base_models_config[name]\n",
    "        \n",
    "        ver, desc = get_run_input(name, \"Tuned\")\n",
    "        \n",
    "        m = train_evaluate_log(\n",
    "            model_name=name,\n",
    "            model=model_inst,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test, y_test=y_test,\n",
    "            stage=\"Tuned\",\n",
    "            dataset_version=ver,\n",
    "            description=desc,\n",
    "            tune=True, param_dist=param_grids[name], n_iter=6\n",
    "        )\n",
    "        trained_tuned[name] = m\n",
    "\n",
    "# 3. Stacking\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n‚ñ∂Ô∏è  Phase 3: Stacking Ensembles\\n\" + \"-\"*50)\n",
    "\n",
    "# Stacking Baseline\n",
    "ver, desc = get_run_input(\"StackingClassifier\", \"Ensemble_Baseline\")\n",
    "stack_base = StackingClassifier(estimators=[(n, m) for n, m in trained_baseline.items()], final_estimator=LogisticRegression(), n_jobs=-1)\n",
    "train_evaluate_log(\"StackingClassifier\", stack_base, X_train, y_train, X_test, y_test, stage=\"Ensemble_Baseline\", dataset_version=ver, description=desc)\n",
    "\n",
    "# Stacking Tuned\n",
    "ver, desc = get_run_input(\"StackingClassifier\", \"Ensemble_Tuned\")\n",
    "stack_tuned = StackingClassifier(estimators=[(n, m) for n, m in trained_tuned.items()], final_estimator=LogisticRegression(), n_jobs=-1)\n",
    "train_evaluate_log(\"StackingClassifier\", stack_tuned, X_train, y_train, X_test, y_test, stage=\"Ensemble_Tuned\", dataset_version=ver, description=desc)\n",
    "\n",
    "# Final Display\n",
    "display(leaderboard.sort_values(by=\"F1_Weighted\", ascending=False).style.background_gradient(subset=[\"F1_Weighted\"], cmap=\"Greens\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbbcdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
